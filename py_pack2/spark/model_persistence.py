# You can also use this section to suppress warnings generated by your code:
def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn
warnings.filterwarnings('ignore')

# FindSpark simplifies the process of using Apache Spark with Python

import findspark
findspark.init()

#import functions/Classes for sparkml

from pyspark.ml.regression import LinearRegression
from pyspark.ml.feature import VectorAssembler
from pyspark.sql import SparkSession
from pyspark.ml import Pipeline, PipelineModel

# import functions/Classes for metrics
from pyspark.ml.evaluation import RegressionEvaluator
spark = SparkSession.builder.appName("Model Persistence").getOrCreate()
mpg_data = spark.read.csv("mpg.csv", header=True, inferSchema=True)
mpg_data.printSchema()
mpg_data.show(5)
# Prepare feature vector
assembler = VectorAssembler(inputCols=["Cylinders", "Engine Disp", "Horsepower", "Weight", "Accelerate", "Year"], outputCol="features")
mpg_transformed_data = assembler.transform(mpg_data)
mpg_transformed_data.select("features","MPG").show()
(training_data, testing_data) = mpg_transformed_data.randomSplit([0.7, 0.3])
# Train linear regression model
# Ignore any warnings
lr = LinearRegression(labelCol="MPG", featuresCol="features")
pipeline = Pipeline(stages=[lr])
model = pipeline.fit(training_data)
#保存model,这个默认去找hdfs去了，我本地无法运行
model.write().overwrite().save(path="file:///D:/software/workspace-py/pythonProject2/model_storage/")

loaded_model = PipelineModel.load("file:///D:/software/workspace-py/pythonProject2/model_storage/")
predictions = loaded_model.transform(testing_data)
predictions.select("prediction").show(5)
